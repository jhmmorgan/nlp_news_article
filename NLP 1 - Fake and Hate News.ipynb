{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invisible-synthetic",
   "metadata": {},
   "source": [
    "# NLP 1. Fake News and Hate Speech identifier\n",
    "\n",
    "**James Morgan (jhmmorgan)**\n",
    "\n",
    "_2022-05-04_\n",
    "\n",
    "# üìñ Background\n",
    "\n",
    "We want a proof of concept, where an end user can easily be provided with a summary of a news article, along with a warning on whether the text is likely to contain hate speech or fake news.\n",
    "\n",
    "This proof of concept would be in the form of a standalone application that when provided the URL to a news article, provides the end-user with the summary of the article, along with a flag if the article may contain hate speech or fake news.\n",
    "\n",
    "### The Task\n",
    "This notebook is **Part 1** of my NLP project.  The task of this notebook is to create usable models that can help us predict if an article of text might contain either hate speech or fake news.\n",
    "\n",
    "# üìö Libraries and functions\n",
    "We'll start by loading the libraries, the majority of which are sklearn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "typical-customs",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from nlp_models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-links",
   "metadata": {},
   "source": [
    "---\n",
    "## Hate Speech\n",
    "\n",
    "We want to create a hate speech prediction mode.  We can do this using a database of tweets that have already been labeled as either hate speech (1) or not hate speech (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indonesian-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Set\u001b[0m\n",
      "Shape: (31962, 3), Len: 31962\n",
      "\n",
      "\u001b[1;4mHead of training set\u001b[0m\n",
      "   id  label                                              tweet\n",
      "0   1      0   @user when a father is dysfunctional and is s...\n",
      "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  #model   i love u take with u all the time in ...\n",
      "4   5      0             factsguide: society now    #motivation\n",
      "\n",
      "\u001b[1mTweet No. 1\u001b[0m\n",
      "@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\n",
      "\u001b[1mTweet No. 22768\u001b[0m\n",
      "imagine how r founding fathers wldve handled muslim terrorism. contrast that w/the limp-dicked pc bullshit of the @user admin  \n"
     ]
    }
   ],
   "source": [
    "hs_train = pd.read_csv(\"./data/hate speech/train.csv\")\n",
    "\n",
    "print2.bold(\"Training Set\")\n",
    "print(f\"Shape: {hs_train.shape}, Len: {len(hs_train)}\")\n",
    "print()\n",
    "print2.heading(\"Head of training set\")\n",
    "print(hs_train.head())\n",
    "print()\n",
    "print2.bold(\"Tweet No. 1\")\n",
    "print(hs_train.tweet.iloc[1])\n",
    "print2.bold(\"Tweet No. 22768\")\n",
    "print(hs_train.tweet.iloc[22768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-emergency",
   "metadata": {},
   "source": [
    "#### Building the model\n",
    "We'll want to feed our custom model a pipeline that processes and classifies our tweets.\n",
    "\n",
    "1. We want to use **CountVectorizer()** on our tweets.  This creates a matrix of 1's (appears) and 0's (doesn't appear) of one to two words.\n",
    "2. We'll then apply a **TfidfTransformer()** to this matrix, which normalises it.  TF-IDF is an information retrieval and information extraction subtask which aims to express the importance of a word to a document which is part of a collection.\n",
    "3. Finally, we'll apply the **SGDClassifier()**, to classify / predict each normalised matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lonely-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_pipeline = Pipeline([('vect', CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "                         ('tfidf',  TfidfTransformer()),\n",
    "                         ('sgd', SGDClassifier()),])\n",
    "dhs = nlp_model(dhs_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-pillow",
   "metadata": {},
   "source": [
    "We then want to split our data into training and testing data sets, to validate our results.  However, prior to doing this, we'll want to resample our data using our custom resample function.  This function will resample all minority labels to appear the same number of times as the majority label.\n",
    "\n",
    "In other words, if out of a training set of 1000 tweets, 700 were not hate speech but 300 were, this would resample / reuse the 300 tweets, so that there was 700 each totalling 1400 tweets.  This helps prevent bias towards the majority label.\n",
    "\n",
    "We then use this to fit (and if applicable, save) our model, before predicting the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modular-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_train = dhs.resample(hs_train, \"label\")\n",
    "hs_X_train, hs_X_test, hs_y_train, hs_y_test = train_test_split(hs_train['tweet'], hs_train['label'], random_state = dhs.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finnish-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs.fit(hs_X_train, hs_y_train)\n",
    "#dhs.save_model(\"./models/hate_speech_v1.pkl\")\n",
    "#dhs = nlp_model()\n",
    "#dhs.load_model(\"./models/hate_speech_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tender-smell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAccuracy: 98.09%\u001b[0m\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "      0     1\n",
      "0  7105   253\n",
      "1    37  7465\n",
      "\n",
      "\u001b[1;4mSamples of each prediction outcome\u001b[0m\n",
      "\u001b[1mTrue Positive\u001b[0m\n",
      "this idiot makes my blood boil!  #pig #liar \n",
      "seems like @user \"#canadianvalues\" are ignoring reality, dividing &amp; weakening, #hate &amp; . #science #cdnpoli√¢¬Ä¬¶ \n",
      "\u001b[1mTrue Negative\u001b[0m\n",
      "@user is this for real? #waspi 50sborn in abject povey but we are all in it together! @user  \n",
      "shit happens but life goes on. good bless√∞¬ü¬ô¬è√∞¬ü¬è¬ª√∞¬ü¬ô¬å√∞¬ü¬è¬ª   days\n",
      "\u001b[1mFalse Positive\u001b[0m\n",
      "i literally bleed for you. don't fucking tell me you don't want my help. fuck you.   #takeitoutonme #fuck\n",
      "jokes on you √∞¬ü¬ò¬é #suicidesquad #thejoker #2016 #jaredleto   \n",
      "\u001b[1mFalse Negative\u001b[0m\n",
      "@user my story: how #race and  have played a role in my life -  \n",
      "anothr #bloated  #jerodtwin #colluder #angrygaymafia #koolaid #guzzling #hasbeen #failure #flushed√∞¬ü¬ö¬Ω√¢¬Ä¬¶ \n"
     ]
    }
   ],
   "source": [
    "hs_y_predict = dhs.predict(hs_X_test)\n",
    "output_score(hs_y_test, hs_y_predict, [0, 1], f1_score)\n",
    "\n",
    "filter_TP = ((hs_y_test == 1) & (hs_y_predict == 1))\n",
    "filter_TN = ((hs_y_test == 0) & (hs_y_predict == 0))\n",
    "filter_FP = ((hs_y_test == 0) & (hs_y_predict == 1))\n",
    "filter_FN = ((hs_y_test == 1) & (hs_y_predict == 0))\n",
    "\n",
    "print()\n",
    "print2.heading(\"Samples of each prediction outcome\")\n",
    "print_samples(2, hs_X_test, filter_TP, title = \"True Positive\")\n",
    "print_samples(2, hs_X_test, filter_TN, title = \"True Negative\")\n",
    "print_samples(2, hs_X_test, filter_FP, title = \"False Positive\")\n",
    "print_samples(2, hs_X_test, filter_FN, title = \"False Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-draft",
   "metadata": {},
   "source": [
    "---\n",
    "## Fake News\n",
    "\n",
    "We now want to create a fake news prediction mode.  We can do this using a database of articles that have already been labeled as either fake news, or real news.  To match the output of the hate speech, we'll also amend the labels from FAKE and REAL to 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amateur-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Set\u001b[0m\n",
      "Shape: (6335, 4), Len: 6335\n",
      "\n",
      "\u001b[1;4mHead of training set\u001b[0m\n",
      "   Unnamed: 0                                              title  \\\n",
      "0        8476                       You Can Smell Hillary‚Äôs Fear   \n",
      "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4         875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text  label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...      1  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      1  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...      0  \n",
      "3  ‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...      1  \n",
      "4  It's primary day in New York and front-runners...      0  \n",
      "\n",
      "\u001b[1mArticle No. 2\u001b[0m\n",
      "\u001b[4mWatch The Exact Moment Paul Ryan Committed Political Suicide At A Trump Rally (VIDEO)\u001b[0m\n",
      "U.S. Secretary of State John F. Kerry said Monday that he will stop in Paris later this week, amid criticism that no top American officials attended Sunday‚Äôs unity march against terrorism.\n",
      "\n",
      "Kerry said he expects to arrive in Paris Thursday evening, a...\n"
     ]
    }
   ],
   "source": [
    "fn_train = pd.read_csv(\"./data/fake_news.csv\")\n",
    "fn_train = fn_train.replace({\"label\" : {\"FAKE\" : 1, \"REAL\" : 0}})\n",
    "\n",
    "print2.bold(\"Training Set\")\n",
    "print(f\"Shape: {fn_train.shape}, Len: {len(fn_train)}\")\n",
    "print()\n",
    "print2.heading(\"Head of training set\")\n",
    "print(fn_train.head())\n",
    "print()\n",
    "print2.bold(\"Article No. 2\")\n",
    "print2.underlined(fn_train.title.iloc[1])\n",
    "print(fn_train.text.iloc[2][0:250] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-index",
   "metadata": {},
   "source": [
    "#### Building the model\n",
    "We'll want to feed our custom model a pipeline that processes and classifies our articles. Whilst the approach is similar to our hate speech model, we'll be using a different pipeline.\n",
    "\n",
    "1. We start the same, using a **CountVectorizer()** on our article.  This creates a matrix of 1's (appears) and 0's (doesn't appear) of one to two words.\n",
    "2. We'll then apply a **TfidfTransformer()** as before to this matrix, which normalises it.  TF-IDF is an information retrieval and information extraction subtask which aims to express the importance of a word to a document which is part of a collection.\n",
    "3. However, rather than applying the **SGDClassifier()**, to classify / predict each normalised matrix, we'll use a **PassiveAggresiveClassifer**, which is useful when working on large data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charitable-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_pipeline = Pipeline([('vect', CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "                         ('tfidf',  TfidfTransformer()),\n",
    "                         ('pac',   PassiveAggressiveClassifier(max_iter=100)),])\n",
    "\n",
    "\n",
    "dfn = nlp_model(dfn_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-partition",
   "metadata": {},
   "source": [
    "As before, we then want to split our data into training and testing data sets, to validate our results.  However, prior to doing this, we'll want to resample our data using our custom resample function.  This function will resample all minority labels to appear the same number of times as the majority label.\n",
    "\n",
    "We then use this to fit (and if applicable, save) our model, before predicting the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grave-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train = dhs.resample(fn_train, \"label\")\n",
    "fn_X_train, fn_X_test, fn_y_train, fn_y_test = train_test_split(fn_train['text'], fn_train['label'], random_state = dhs.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genuine-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.fit(fn_X_train, fn_y_train)\n",
    "dfn.save_model(\"./models/fake_news_v1.pkl\")\n",
    "dfn = nlp_model()\n",
    "dfn.load_model(\"./models/fake_news_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wicked-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAccuracy: 96.15%\u001b[0m\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "     0    1\n",
      "0  773   37\n",
      "1   24  752\n",
      "\n",
      "\u001b[1;4mSamples of each prediction outcome\u001b[0m\n",
      "\u001b[1mTrue Positive\u001b[0m\n",
      "Here‚Äôs the timing: \n",
      "Most of the US will have to wait for polling stations to close ‚Äì typically between 19:00 EST (00:00 GMT) and 20:00 EST (01:00 GMT) ‚Äì for state projections. \n",
      "As for the final result? Stay glued to your phone or TV or set your alarm for 23:00 EST (04:00 GMT). That‚Äôs when West Coast polls close and history suggests a winner‚Äôs declared. It was bang on the hour in 2008, and 15 minutes later in 2012. \n",
      "Of course, if you go further back in history, 2004 was a nailbiter. I remember very well going to bed after the Kerry campaign said they‚Äôd challenge the result based on Ohio, and getting up in the morning to find out they‚Äôd caved. And of course election 2000 was what it was. \n",
      "There will be many sites tracking the results as they come in; here‚Äôs Politico‚Äôs for the presidency (they also have the House and the Senate). It‚Äôs impossible to know which one is the best until data actually appears; I prefer maps with results as they come in by county. And speaking of counties‚Ä¶ \n",
      "The final RCP averages put Clinton ahead in the national popular vote by 3.3%. However, with Trump ahead in Florida (0.02%), North Carolina (1%), and Clinton only ahead by 0.5% in New Hampshire, it still looks like a horse race, to me. (Of course, I may have become counter-suggestible to the idea that Clinton has it in the bag because almost the entire political class is yammering that she does.) \n",
      "Anyhow, if indeed this is a horse race ‚Äî and if our famously free press doesn‚Äôt simply decide to call it ‚Äî we‚Äôll be up late waiting for county data in the states that are close (presumably swing states like Florida, North Carolina, and New Hampshire). So here is a table of the counties that various sources regard as key:\n",
      "\u001b[1mFalse Positive\u001b[0m\n",
      "‚ÄúI felt it is important to take the opportunity to meet the President-elect now before the drumbeats of war that neocons have been beating drag us into...\n"
     ]
    }
   ],
   "source": [
    "fn_y_predict = dfn.predict(fn_X_test)\n",
    "output_score(fn_y_test, fn_y_predict, [0, 1], accuracy_score)\n",
    "\n",
    "filter_TP = ((fn_y_test == 1) & (fn_y_predict == 1))\n",
    "filter_TN = ((fn_y_test == 0) & (fn_y_predict == 0))\n",
    "filter_FP = ((fn_y_test == 0) & (fn_y_predict == 1))\n",
    "filter_FN = ((fn_y_test == 1) & (fn_y_predict == 0))\n",
    "\n",
    "print()\n",
    "print2.heading(\"Samples of each prediction outcome\")\n",
    "print_samples(1, fn_X_test, filter_TP, title = \"True Positive\")\n",
    "#print_samples(1, fn_X_test, filter_TN, title = \"True Negative\")\n",
    "print_samples(1, fn_X_test, filter_FP, title = \"False Positive\")\n",
    "#print_samples(1, fn_X_test, filter_FN, title = \"False Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-repair",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# üéì Summary\n",
    "This concludes the first part of our NLP project.  Using a simple custom model class that we load in, we create two models, one that predicts if text is hate speech and another to predict if the text is fake news.\n",
    "\n",
    "We save both trained models, to be used in our final part, where we bring all of our NLP models together.\n",
    "\n",
    "It should be noted that neither model is too complicated. We don't validate the source of articles, nor do we provide a list of unsafe words to flag, or understand the context of the message (e.g. a reply to a tweet may not appear to be hate speech when read alone, but with the context of the original tweet, it may very well be hate speech).\n",
    "\n",
    "That said, the models remain fairly effective because it is good at picking up the patterns that are typically seen in hate speech or fake news."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.9)",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
